* ERAD RS 2019 - Leitura e resumo dos slides 
** Modelo PCAM

   Apresentação de conceitos para construção de programas paralelos:

   - Particionamento
   - Comunicação
   - Aglomeração
   - Mapeamento

   Etapas:
   - Particionamento / Comunicação: *Focam na escabilidade de uma
     solução*. 
     - Procurar algoritmos que oferecem um paralelismo extremo;
     - A maior concorrência possível entre as unidades de
       processamento; 

   - Aglomeração / Mapeamento: *Focam na preocupação com desempenho*. 
     - Necessita de conhecimentos de configuração da plataforma de
       execução.
     - Como mapear para os recursos computacionais.
     - Como balancear a carga.

   Provavelmente esse tipo de técnica pode ser aplicada de maneira
   cíclica.

*** Particionamento
    *Objetivo:* Descobrir oportunidades de paralelismo.
     - Identificar operações que podem ser utilizadas em paralelo.
     - Identificar a menor operação possível, a menor *granulidade
       (grão)*.

    Um tamanho muito pequeno para operação poderia causar problemas,
    como: comunicação excessiva e tarefas demais.

**** Particionamento de dados (decomposição de domínio)
       *Objetivo:* Particionamento do problema com enfoque em seus
        dados.
       Cada pedaço do problema terá os dados e suas operações,
        usualmente dividos num mesmo tamanho.

**** Particionamento de operações (decomposição funcional)
       *Objetivo:* Particionamento do problema com enfoque em suas
        operações.
       Divide-se as operações que podem ser executadas de maneira
        concorrente, criando *partes funcionais.*
*** Comunicação
    *Objetivo:* Fase essencial para que os processos conversem entre si,
     compartilhando informações; no entanto, a comunicação implica em
     sincronização, o que *prejudica o alto desempenho.*

**** Definições
       - *Local:* Necessita dados de poucas partições vizinhas.
       - *Global:* Necessita dados de todas as partições.
       - *Assíncrona :* O emissor não sabe quando os dados serão
         utilizados, apenas os envia.
       - *Síncrona :* Emissor e receptor estão cientes quando a operação
         acontece.
*** Aglomeração
    *Objetivo :* Tornar o algortimo mais realista, considerando os
     limites impostos pela plataforma alvo. E também, obter um
     programa eficiente na plataforma, aumentando a localidade do
     cálculo.
   *Benefícios :*
   - Impacto em diretivas de comunicação.
   - Benefícios da replicação de dados e operações.
   - Necessidade da redução drástica do número total de tarefas (uma
     por unidade de processamento).
*** Mapeamento
    *Objetivo :* Definir onde cada tarefa será executada. É uma tarefa
    complexa, pois: 
    - Deve ser explícito em supercomputadores de alto desempenho.
    - Soluções simples podem ser empregados; entretanto, com um baixo
      desempenho.

**** Mapeamento simples
     *Pré-condições :*
     - Custo computacional das tarefas é *estático* (ao longo do tempo)
     - Custo computacional das tarefas é *homogêneo* (entre as
       partições)
     - Supercomputador tem capidade *homogênea*, e a rede de
       interconexão também.

     *Aglomeramos as partições para ter uma por núcleo,* *assim
     evitamos* *ao máximo a comunicação.*
     
**** Mapeamento mais complexo
     Cenário onde as partições tem custos computacionais diferentes
     (*heterogêneas*), ainda que sejam estáticas ao longo do tempo de
     execução.

***** Algoritmos de balanceamento de carga
      Estes algoritmos permitem equilibrar o cálculo, e também
      encontrar a melhor granulidade.

****** Bisseção recursiva (*Barnes-Hut, centralizado/distribuído*)
       - *Simples :* unicamente pelas coordenadas.
       - *Melhor :* método de balanceamento (somente *comunicações*).
       - *Bisseção recursiva :* para malhas irregulares.

****** Balanceamento de carga local
       Algoritmo distribuído.
***** Escalonamento de tarefas 
      Existe um *maestro* escalonador que define em quais núcleos de
      processamento as tarefas irão executar.

      *Funcionamento :* /poll of problems/
      O maestro equipa-se de uma heurística de escalonamento, onde ele
      decide durante a execução onde mapear as tarefas.

     
* SIMGRID
** Instalação no Mac OSX

*** Instalação da biblioteca C *Boost*:

   #+begin_src shell
   brew install boost
   #+end_src

*** Download do SIMGRID no site oficial:
    
   [[https://simgrid.org][Site oficial]]

*** Extrair o arquivo:

   #+begin_src shell 
   tar -xvf SimGrid-x.x.x.tar.gz  
   #+end_src

*** Entrar no diretório:

   #+begin_src shell
   cd SimGrid-x.x.x
   #+end_src

*** Gerar todos os /makefiles/ (assumindo que você deseja instalar no /folder/ /usr/local):

   #+begin_src shell
   cmake -DCMAKE_INSTALL_PREFIX=/usr/local -Denable_smpi=on -Denable_documentation=off
   #+end_src

*** Alterar no arquivo *CmakeCache.txt* de */usr/bin/python* para */usr/bin/python3*
*** Compilar os arquivos:
  
   #+begin_src shell
   make
   #+end_src

*** Executar os testes:

   #+begin_src shell 
   make check
   #+end_src

*** Instalar bibliotecas e executáveis:

   #+begin_src shell
   sudo make install
   #+end_src

*** Versões para instalação

   *Cmake 3.15.1*
   *Python 3+*
** Descrevendo as plataformas de simulação
   Para utilização do *SMPI* é necessário descrever qual a topologia do
   ambiente, e para isso utiliza-se um arquivo XML contendo
   informações dos /hosts/ e dos /links/ que os interligam.

*** Três /hosts/

    Uma das topologias mais simples que foram apresentadas, contém 3
    /hosts/ conectados através de 3 /links/, onde existe um /host/ com muito
    poder computacional (host2), 40 vezes mais que o host0, e o link2
    possuindo 5 vezes mais velocidade que o link1.

    #+CAPTION: Figura que demonstra a topologia com 3 hosts interconectados.
    #+NAME: fig:3-HOSTS
    [[./img/3-host.png]]
    #+begin_src xml
<?xml version='1.0'?>
<!DOCTYPE platform SYSTEM "http://simgrid.gforge.inria.fr/simgrid/simgrid.dtd">
<platform version="4.1">
   <zone id="AS0" routing="Full">
     <host id="host0" speed="1Gf"/>
     <host id="host1" speed="2Gf"/>
     <host id="host2" speed="40Gf"/>
     <link id="link0" bandwidth="125MBps" latency="100us"/>
     <link id="link1" bandwidth="50MBps" latency="150us"/>
     <link id="link2" bandwidth="250MBps" latency="50us"/>
     <route src="host0" dst="host1"><link_ctn id="link0"/><link_ctn id="link1"/></route>
     <route src="host1" dst="host2"><link_ctn id="link1"/><link_ctn id="link2"/></route>
    <route src="host0" dst="host2"><link_ctn id="link0"/><link_ctn id="link2"/></route>
  </zone>
</platform>
    
    #+end_src

*** /Cluster/ homogêneo com um /crossbar switch/

    Uma plataforma de processamento paralelo muito comum é um /cluster/
    homogêneo, contendo N /hosts/ conectados em um /switch/ que é muito
    mais rápido que as conexões, portanto sua latência e banda são
    desconsideradas.

    #+CAPTION: Figura que demonstra a topologia com um crossbar switch.
    #+NAME: fig:CROSSBAR

    [[./img/crossbar.png]]


    #+begin_src xml
<?xml version='1.0'?>
<!DOCTYPE platform SYSTEM "http://simgrid.gforge.inria.fr/simgrid/simgrid.dtd">
<platform version="4.1">
    <zone id="AS0" routing="Full">
        <cluster id="my_cluster" prefix="host-" suffix=".hawaii.edu" radical="0-255" speed="1Gf" bw="125Mbps" lat="5us"/>
    </zone>
</platform>
    
    #+end_src

*** /Cluster/ homogêneo com um /backbone/ compartilhado
    
    Uma plataforma de processamento paralelo muito comum é um /cluster/
    homogêneo conectado a um meio de comunicação compartilhado, um
    /backbone/, que contém capacidade de banda finita.

    #+CAPTION: Figura que demonstra a topologia com um backbone shared.
    #+NAME: fig:BACKBONE

    [[./img/backbone.png]]

    #+begin_src xml
<?xml version='1.0'?>
<!DOCTYPE platform SYSTEM "http://simgrid.gforge.inria.fr/simgrid/simgrid.dtd">
<platform version="4.1">
  <zone id="AS0" routing="Full">
    <cluster id="my_cluster" prefix="host−" suffix=".hawaii.edu" radical="0−255" speed="1Gf" bw="125Mbps" lat="50us" bb_bw="2.25Gbps" bb_lat="500us"/>
  </zone>
</platform>

    #+end_src

*** Dois /clusters/ conectados

    É possível conectar /clusters/ e de fato construir ambientes de
    procesamento paralelo com hierarquias. 


    #+CAPTION: Figura que demonstra a topologia com dois clusters conectados.
    #+NAME: fig:2-CLUSTERS
    [[./img/2-clusters.png]]

    #+begin_src xml
<?xml version='1.0'?>
<!DOCTYPE platform SYSTEM "http://simgrid.gforge.inria.fr/simgrid/simgrid.dtd">
<platform version="4.1">
  <zone id="AS0" routing="Full">
    <cluster id="my_cluster_1" prefix="C1−" suffix=".hawaii.edu" radical="0−15" speed="1Gf" bw="125Mbps" lat="50us" bb_bw="2.25Gbps" bb_lat="500us" />
    <cluster id="my_cluster_2" prefix="C2−" suffix=".hawaii.edu" radical="0−31" speed="2Gf" bw="125Mbps" lat="50us" />
    <link id="internet_backbone" bandwidth="0.01Gbps" latency="22500us" />
    <zoneRoute src="my_cluster_1" dst="my_cluster_2" gw_src="C1−my_cluster_1_router.hawaii.edu" gw_dst="C2−my_cluster_2_router.hawaii.edu" symmetrical="YES">
      <link_ctn id="internet_backbone" />
    </zoneRoute>
  </zone>
</platform>
    
    #+end_src
